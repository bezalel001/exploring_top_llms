{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7dc0bac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from pprint import pprint\n",
    "from pydantic import SecretStr\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_groq import ChatGroq\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv('.env')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f62800",
   "metadata": {},
   "source": [
    "## Coding With OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92b76b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"gpt-4o-mini\"\n",
    "_key = os.getenv('OPENAI_API_KEY')\n",
    "api_key = SecretStr(_key) if _key is not None else None\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    model=MODEL_NAME,\n",
    "    temperature=0.5,  # controls creativity\n",
    "    api_key=api_key,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5bab7189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': 'LangChain is a framework designed to facilitate the development of applications that utilize large language models (LLMs). It provides a structured way to build applications that can integrate various components such as data sources, APIs, and other tools, enabling developers to create more complex and capable applications powered by LLMs.\\n\\nKey features of LangChain include:\\n\\n1. **Modularity**: LangChain allows developers to work with different components (like prompts, memory, and chains) independently, making it easier to build and customize applications.\\n\\n2. **Chains**: It supports the creation of chains, which are sequences of calls to language models or other functions. This allows for more complex workflows, where the output of one step can be used as input for the next.\\n\\n3. **Integrations**: LangChain can connect to various data sources and external APIs, enabling applications to pull in real-time data or interact with other services.\\n\\n4. **Memory Management**: It provides mechanisms for managing state and memory, allowing applications to remember previous interactions or context, which can enhance user experiences.\\n\\n5. **Prompt Management**: LangChain includes tools for designing and managing prompts, which are essential for guiding the behavior of language models effectively.\\n\\nOverall, LangChain is aimed at making it easier for developers to harness the power of LLMs in their applications, enabling more sophisticated interactions and functionalities.',\n",
       " 'additional_kwargs': {'refusal': None},\n",
       " 'response_metadata': {'token_usage': {'completion_tokens': 274,\n",
       "   'prompt_tokens': 12,\n",
       "   'total_tokens': 286,\n",
       "   'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
       "    'audio_tokens': 0,\n",
       "    'reasoning_tokens': 0,\n",
       "    'rejected_prediction_tokens': 0},\n",
       "   'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}},\n",
       "  'model_provider': 'openai',\n",
       "  'model_name': 'gpt-4o-mini-2024-07-18',\n",
       "  'system_fingerprint': 'fp_560af6e559',\n",
       "  'id': 'chatcmpl-CWIuBXr0LLsGR2svteXBc2dfu0h5r',\n",
       "  'service_tier': 'default',\n",
       "  'finish_reason': 'stop',\n",
       "  'logprobs': None},\n",
       " 'type': 'ai',\n",
       " 'name': None,\n",
       " 'id': 'lc_run--1eaf2adb-2207-447b-aa16-d878f751f92f-0',\n",
       " 'tool_calls': [],\n",
       " 'invalid_tool_calls': [],\n",
       " 'usage_metadata': {'input_tokens': 12,\n",
       "  'output_tokens': 274,\n",
       "  'total_tokens': 286,\n",
       "  'input_token_details': {'audio': 0, 'cache_read': 0},\n",
       "  'output_token_details': {'audio': 0, 'reasoning': 0}}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = model.invoke('What is LangChain?')\n",
    "res.model_dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cdeaa6b",
   "metadata": {},
   "source": [
    "## Coding Using Groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18b5935c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'llama-3.3-70b-versatile'\n",
    "model = ChatGroq(model=MODEL_NAME, temperature=0.5, api_key=os.getenv('GROK_API_KEY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "608334fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.invoke('What is Groq?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fc7eb1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': \"Groq is a technology company that specializes in the development of high-performance computing hardware and software. They are particularly known for their work on tensor processing units (TPUs) and other accelerated computing solutions.\\n\\nGroq was founded in 2016 by a team of experienced engineers and researchers from companies like Google, Intel, and Stanford University. The company is headquartered in Mountain View, California.\\n\\nGroq's main product is the Groq Tensor Processing Unit (TPU), a custom-built ASIC (Application-Specific Integrated Circuit) designed specifically for machine learning and artificial intelligence workloads. The Groq TPU is optimized for performance, power efficiency, and scalability, making it suitable for a wide range of applications, from cloud computing to edge devices.\\n\\nGroq's technology has gained significant attention in the industry, and the company has partnered with several major players in the field, including Google, Amazon, and Microsoft. They have also received funding from prominent investors, such as Social Capital and TDK Ventures.\\n\\nOverall, Groq is an innovative company that is pushing the boundaries of high-performance computing and artificial intelligence, and their technology has the potential to make a significant impact in various fields, from cloud computing to autonomous vehicles and healthcare.\",\n",
       " 'additional_kwargs': {},\n",
       " 'response_metadata': {'token_usage': {'completion_tokens': 245,\n",
       "   'prompt_tokens': 40,\n",
       "   'total_tokens': 285,\n",
       "   'completion_time': 0.659406868,\n",
       "   'prompt_time': 0.001948275,\n",
       "   'queue_time': 0.172769338,\n",
       "   'total_time': 0.661355143},\n",
       "  'model_name': 'llama-3.3-70b-versatile',\n",
       "  'system_fingerprint': 'fp_55062f05af',\n",
       "  'service_tier': 'on_demand',\n",
       "  'finish_reason': 'stop',\n",
       "  'logprobs': None,\n",
       "  'model_provider': 'groq'},\n",
       " 'type': 'ai',\n",
       " 'name': None,\n",
       " 'id': 'lc_run--4facd59f-b615-4734-92f8-8b50815a9bc4-0',\n",
       " 'tool_calls': [],\n",
       " 'invalid_tool_calls': [],\n",
       " 'usage_metadata': {'input_tokens': 40,\n",
       "  'output_tokens': 245,\n",
       "  'total_tokens': 285}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6393be64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Groq is a technology company that specializes in the development of '\n",
      " 'high-performance computing hardware and software. They are particularly '\n",
      " 'known for their work on tensor processing units (TPUs) and other accelerated '\n",
      " 'computing solutions.\\n'\n",
      " '\\n'\n",
      " 'Groq was founded in 2016 by a team of experienced engineers and researchers '\n",
      " 'from companies like Google, Intel, and Stanford University. The company is '\n",
      " 'headquartered in Mountain View, California.\\n'\n",
      " '\\n'\n",
      " \"Groq's main product is the Groq Tensor Processing Unit (TPU), a custom-built \"\n",
      " 'ASIC (Application-Specific Integrated Circuit) designed specifically for '\n",
      " 'machine learning and artificial intelligence workloads. The Groq TPU is '\n",
      " 'optimized for performance, power efficiency, and scalability, making it '\n",
      " 'suitable for a wide range of applications, from cloud computing to edge '\n",
      " 'devices.\\n'\n",
      " '\\n'\n",
      " \"Groq's technology has gained significant attention in the industry, and the \"\n",
      " 'company has partnered with several major players in the field, including '\n",
      " 'Google, Amazon, and Microsoft. They have also received funding from '\n",
      " 'prominent investors, such as Social Capital and TDK Ventures.\\n'\n",
      " '\\n'\n",
      " 'Overall, Groq is an innovative company that is pushing the boundaries of '\n",
      " 'high-performance computing and artificial intelligence, and their technology '\n",
      " 'has the potential to make a significant impact in various fields, from cloud '\n",
      " 'computing to autonomous vehicles and healthcare.')\n"
     ]
    }
   ],
   "source": [
    "pprint(result.model_dump()['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39618476",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
