{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85efe236",
   "metadata": {},
   "source": [
    "# Model Parameters & Model Selection\n",
    "\n",
    "Model parameters like temperature, top-p, and tok-k allow you to fine-tune the generated model outputs. With them you can control the creativity, randomness and focus of the generated output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0cf31fb",
   "metadata": {},
   "source": [
    "### Model Temperature\n",
    "With model temperature, you can control the randomness of the model's ouput. \n",
    "- 0 for low temperature\n",
    "- 1 or higher  for high temperature\n",
    "With low temperatures you can repeatedly get the same result as the model is focused and deterministic.\n",
    "With high tempetures increases the randomnes of token selection which leads to more chaotic and incoherent outputs. This may also lead to a more creative output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381f9763",
   "metadata": {},
   "source": [
    "### Top-p and Top-k\n",
    "Nucleus sampling or top-p controls the probability of the nest token by dynamically adjusting the number of possible tokens that the model can choose. with top-p=0.8, only 80% of the tokens are considered. with top-p=1.0 all tokens are considered. with top-p=0.4 only 40% of the tokens are considered so the outputs tend to be more focused and predictable\n",
    "\n",
    "Top-k sampling controls how many of the most probable tokens are considered when generating the next word. For top-k=1, only the most probable token is chosen. For top-k=40, the model has 40 token options.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17aa2c3b",
   "metadata": {},
   "source": [
    "## Model Selection\n",
    "\n",
    "How do you select the right model for your task? The answer to this question depends on your task and budget. E.g you may need to consider the context window if you need to process long input prompts. If you need accurate output you need to consider the performance. If you need quick response, e.g for real-time apps, you may need to consider the latency. Depending on the data you work with, you may need on-premise hosting or cloud hosting for the model. The model cutoff date may also be important if you want the output to contain recent developments and trends. Although most models are models are equipped with internet search capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ebe92b",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exploring-top-llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
