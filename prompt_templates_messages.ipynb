{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64428ae1",
   "metadata": {},
   "source": [
    "# Messages and Prompt Templates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f57123",
   "metadata": {},
   "source": [
    "## Messages\n",
    "To call a model we need to specify the model name and  add a message. Multiple types of messages are used. Each message has a role and content. The most coomon message types are `user`, `system` and `assistant`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30e9f37",
   "metadata": {},
   "source": [
    "### User\n",
    "This message represent the user input. The effectiveness of an LLM response depends on the clarity of the user messsage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6386bb45",
   "metadata": {},
   "source": [
    "### System\n",
    "This message defines how the model should behave and work, like in a role play.\n",
    "For example, if you want to set up a general assistant, a typical system message might be as follows:\n",
    "\n",
    "`You are are a helpful AI assistant designed to provide accurate, concise, and polite responses. Always ensure that your answers are clear and informative`\n",
    "\n",
    "Alternatively, imagine you want your model to behave as a technical support assistant. In this case, you might instruct the model with the following system message\n",
    "\n",
    "`You are a technical support AI assistant specializing in troubleshooting and explaining software-related issues. Respond with clear, step-by-step instructions, avoiding technical jargon whenever possible`\n",
    "\n",
    "The system message is critical for setting the model's boundaries and expectations and helps guide it to behave in a manner aligned with user's requirements. Although system messages cannot enforce strict adherence to the expectations through out the conversations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ba7c08",
   "metadata": {},
   "source": [
    "### Assistant\n",
    "The assistant message type corresponds to the model response. It has a property `content` which holds the model output and also a `response_metadata` property which contains the token usage and the duration the query took among other model-specific output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be4f20e",
   "metadata": {},
   "source": [
    "## Prompt templates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11900f97",
   "metadata": {},
   "source": [
    "### `CharPromptTemplates`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ec9ed2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3eb582e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  setup chat prompt template\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You're an AI assistant that translates English into another language.\"),\n",
    "    (\"user\", \"Translate this sentence: '{input}' into {target_language}.\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c52e9b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content=\"You're an AI assistant that translates English into another language.\", additional_kwargs={}, response_metadata={}), HumanMessage(content=\"Translate this sentence: 'I love programming.' into Russian.\", additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Invoke prompt template with variables\n",
    "\n",
    "prompt_template.invoke({\"input\": \"I love programming.\", \"target_language\": \"Russian\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ac6081",
   "metadata": {},
   "source": [
    "### Improve Prompts with Langchain Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30c9a18d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from langsmith import Client\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('.env')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9150d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch prompt template from hub\n",
    "client = Client()\n",
    "\n",
    "prompt = client.pull_prompt(\"hardkothari/prompt-maker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebdd0da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get input variables\n",
    "input_vars = prompt.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8dcf0871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Variables:\n",
      "['lazy_prompt', 'task']\n"
     ]
    }
   ],
   "source": [
    "print(\"Input Variables:\")\n",
    "pprint(input_vars)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73c9f0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  model\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# chain\n",
    "chain = prompt | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11169e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run chain\n",
    "lazy_prompt = \"summer, vacation, beach\"\n",
    "task = \"Shakepeare poem\"\n",
    "improved_prompt = chain.invoke({\"lazy_prompt\": lazy_prompt, \"task\": task})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6bdc5f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As a master of Shakespearean poetry, compose a sonnet that captures the essence of summer vacation at the beach. \n",
      "\n",
      "### Your poem should evoke vivid imagery and emotions associated with sun-soaked days, gentle ocean waves, and the carefree spirit of leisure. \n",
      "\n",
      "Aim for a traditional Shakespearean sonnet structure, consisting of 14 lines with a rhyme scheme of ABABCDCDEFEFGG. \n",
      "\n",
      "Incorporate themes of joy, nostalgia, and the fleeting nature of summer, while employing rich metaphors and similes characteristic of Shakespeare's style. \n",
      "\n",
      "The final piece should resonate with readers, transporting them to a serene beach setting, and should be approximately 100-120 words in length. \n",
      "\n",
      "Example opening lines: \"When golden rays upon the waters dance...\"\n"
     ]
    }
   ],
   "source": [
    "print(improved_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b88d28b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIMessage(content=\"When golden rays upon the waters dance,  \\nAnd laughter mingles with the ocean's sigh,  \\nThe sun, a sovereign in its warm expanse,  \\nBestows sweet joy beneath the azure sky.  \\n\\nThe gentle waves, like whispers soft and low,  \\nCaress the shore with tender, rhythmic grace,  \\nWhile children chase the tide, their hearts aglow,  \\nIn fleeting moments time cannot erase.  \\n\\nOh, how the salty breeze doth weave a spell,  \\nAs seashells glisten like forgotten dreams,  \\nEach grain of sand a tale it longs to tell,  \\nOf sunlit days and laughter's joyful beams.  \\n\\nYet summer's breath, though sweet, must fade away,  \\nLike fleeting youth, it bids us not to stay.  \", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 156, 'prompt_tokens': 161, 'total_tokens': 317, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_51db84afab', 'id': 'chatcmpl-CZkn1sfFQCnK0WAGW53BNJyQiPRQq', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--3ec66c5c-67d4-4b7e-b316-e2905f5e6cd4-0', usage_metadata={'input_tokens': 161, 'output_tokens': 156, 'total_tokens': 317, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})\n"
     ]
    }
   ],
   "source": [
    "# run model with improved prompt\n",
    "res = model.invoke(improved_prompt)\n",
    "pprint(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6e68e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exploring-top-llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
